{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618854aa-8df4-40d7-b956-638642501e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28b3319-fea6-4aa8-8da8-d3c88a21d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2bafad-be25-4e89-87d6-9234a12dcfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e14b70e4847418dcb26ad3738bf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ed502c6e444497be0d4da61bf9ba69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7ff1c4d30f42b7a64da45182495804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c110a5fa50ca49d4b7804390625e71ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3475f8296b84b8cb0c5714f9a54615d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab the tokenizer only\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c820bd-9bb4-4520-87b8-105e9a6393e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (338025 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 5962, 22307,    25,   198,  8421])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tensor(tokenizer.encode(text))\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45618bf8-69ac-46bf-b90d-d96b025c0f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['hi', 'hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3b5f1b-da64-4cca-944a-19e4f69bb5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1dcef4199b4c74ae72e4d79f64b07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5d431b45e64569990169c8b9397472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/19.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cdacf95f6e4e2f8f6a337c75624925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.csv:   0%|          | 0.00/2.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d5617aeeeb4c2b95f1645a381f12c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/2.43M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbe8aceece64e09a3b98d1c1c777a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/187641 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e594694a9d1f40c1897e63677460ebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/20850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ad8de9454247d6b50c14ff2846cb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/23166 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"myothiha/jokes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c4e458-ed92-4624-9926-cb1ec48ed34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187641"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ds['train']['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5033d2e9-182a-4cc1-bc3e-37b1c5eb6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' [SEP] '.join(ds['train']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374a5ff0-ca55-4e96-82cf-a4c00b6d8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "context_length = 32\n",
    "n_embs = 256\n",
    "n_heads = 8\n",
    "n_blocks = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1678e521-f353-49cb-bd00-070a8844052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19034660"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf0edb3-4b5f-417b-b9d6-03f225622f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataLoader():\n",
    "    def __init__(self, text, context_size, tokenizer, batch_size=1, device='cpu'):\n",
    "        v = tokenizer(text, return_tensors='pt')\n",
    "        self.tokens = v.input_ids # The attention mask will be handled manually later\n",
    "        self.batch_size = batch_size\n",
    "        self.context_length = context_length\n",
    "        self.device = device\n",
    "        \n",
    "        self.position = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.reset()\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        B, T = self.batch_size, self.context_length\n",
    "        if self.position + B * T + 1 < len(self.tokens[0]):\n",
    "            tokens = self.tokens[0][self.position: self.position + B * T + 1]\n",
    "            self.position += self.context_length + B * T + 1\n",
    "            x = tokens[:-1].view(B, T)\n",
    "            y = tokens[1:].view(B, T)\n",
    "            return x.to(self.device), y.to(self.device)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.tokens[0]) // self.context_length // self.batch_size\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bff33-94ea-4d42-8d21-d533aec74ef2",
   "metadata": {},
   "source": [
    "The `head_size` matches that of the embeddings if it is a single head.\n",
    "\n",
    "If multi-headed attention is used, then the `head_size` would equal number of embeddings // number of heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03339711-a3e5-47a4-923d-4f077210e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionHead(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.k = nn.Linear(n_embs, head_size, bias=False)\n",
    "        self.q = nn.Linear(n_embs, head_size, bias=False)\n",
    "        self.v = nn.Linear(n_embs, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.k(x) # (B, T, head_size)\n",
    "        q = self.q(x) # (B, T, head_size)\n",
    "        v = self.v(x) # (B, T, head_size)\n",
    "        \n",
    "        attn = q @ k.transpose(-2, -1) * C ** -0.5 # (B, T, T)\n",
    "        \n",
    "        wei = attn.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) # Causal masking, blocks future tokens from being seen\n",
    "        wei = wei.softmax(dim=-1) # (B, T, T)\n",
    "        \n",
    "        out = wei @ v # (B, T, head_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b400d5-aa6a-4b65-b8d6-dc914cda5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttentionHead(n_embs // n_heads) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embs, n_embs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92b6718-a1ae-4ea6-bcc5-93455857d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embs, n_embs * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embs * 4, n_embs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26fe11e4-11a7-446a-9460-b06516801701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(n_embs)\n",
    "        self.mha = MultiHeadAttention(n_heads)\n",
    "        self.ln2 = nn.LayerNorm(n_embs)\n",
    "        self.ffwd = FeedForward()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.mha(self.ln1(x)) + x\n",
    "        x = self.ffwd(self.ln2(x)) + x\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f0c74a-c31f-4d47-993d-4ee10741d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tk_emb = nn.Embedding(vocab_size, n_embs)\n",
    "        self.pos_emb = nn.Embedding(context_length, n_embs)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock() for i in range(n_blocks)])\n",
    "        self.ln_f = nn.LayerNorm(n_embs)\n",
    "        self.fc = nn.Linear(n_embs, vocab_size)\n",
    "        \n",
    "        self.tk_emb.weight = self.fc.weight\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        tk_emb = self.tk_emb(x) # (B, T, C)\n",
    "        pos_tns = torch.arange(T, device=device) # T\n",
    "        pos_emb = self.pos_emb(pos_tns) # (T, C)\n",
    "        x = pos_emb + tk_emb # (B, T, C) + (T, C)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.ln_f(x)\n",
    "        logits = self.fc(x) # (B, T, vocab_size)\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(B * T, -1), targets.view(B*T))\n",
    "            return logits, loss\n",
    "        \n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67e5f02-78a0-4730-979d-1f31dbab1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9455f490-05c2-4f80-a62a-cca61b1882b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e125af26-a85c-4b2d-96d8-0eb3cd1f50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TextDataLoader(text, 32, tokenizer, batch_size=32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d51a4c1-b096-44d0-9510-8919e2376459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 32]), torch.Size([32, 32]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f48db7-5bb5-4ca9-9a80-164fac5a7bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "855b7de2-f203-495e-b0d6-647583b2a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "opt = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "618a182f-e2a0-42c2-bd90-86e2b2a19ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 11.018798828125\n",
      "Epoch: 0, Step: 200, Loss: 6.7135009765625\n",
      "Epoch: 0, Step: 400, Loss: 6.4780731201171875\n",
      "Epoch: 0, Step: 600, Loss: 6.050868034362793\n",
      "Epoch: 0, Step: 800, Loss: 5.910508632659912\n",
      "Epoch: 0, Step: 1000, Loss: 5.696419715881348\n",
      "Epoch: 0, Step: 1200, Loss: 5.576383113861084\n",
      "Epoch: 0, Step: 1400, Loss: 5.382604598999023\n",
      "Epoch: 0, Step: 1600, Loss: 5.582192420959473\n",
      "Epoch: 0, Step: 1800, Loss: 5.180304050445557\n",
      "Epoch: 0, Step: 2000, Loss: 5.430119514465332\n",
      "Epoch: 0, Step: 2200, Loss: 5.166388511657715\n",
      "Epoch: 0, Step: 2400, Loss: 5.11775541305542\n",
      "Epoch: 0, Step: 2600, Loss: 5.062450885772705\n",
      "Epoch: 0, Step: 2800, Loss: 4.690340042114258\n",
      "Epoch: 0, Step: 3000, Loss: 4.733290672302246\n",
      "Epoch: 0, Step: 3200, Loss: 5.401444911956787\n",
      "Epoch: 0, Step: 3400, Loss: 5.17732572555542\n",
      "Epoch: 0, Step: 3600, Loss: 4.903584957122803\n",
      "Epoch: 0, Step: 3800, Loss: 4.650193214416504\n",
      "Epoch: 0, Step: 4000, Loss: 4.683797359466553\n",
      "Epoch: 0, Step: 4200, Loss: 4.553931713104248\n",
      "Epoch: 0, Step: 4400, Loss: 5.004843711853027\n",
      "Epoch: 0, Step: 4600, Loss: 4.681117057800293\n",
      "Epoch: 0, Step: 4800, Loss: 4.78080940246582\n",
      "Epoch: 1, Step: 0, Loss: 4.8764801025390625\n",
      "Epoch: 1, Step: 200, Loss: 4.609106540679932\n",
      "Epoch: 1, Step: 400, Loss: 4.359270095825195\n",
      "Epoch: 1, Step: 600, Loss: 4.318828582763672\n",
      "Epoch: 1, Step: 800, Loss: 4.566943168640137\n",
      "Epoch: 1, Step: 1000, Loss: 4.532166481018066\n",
      "Epoch: 1, Step: 1200, Loss: 4.494841575622559\n",
      "Epoch: 1, Step: 1400, Loss: 4.4883317947387695\n",
      "Epoch: 1, Step: 1600, Loss: 4.792899131774902\n",
      "Epoch: 1, Step: 1800, Loss: 4.358808517456055\n",
      "Epoch: 1, Step: 2000, Loss: 4.587368488311768\n",
      "Epoch: 1, Step: 2200, Loss: 4.48762845993042\n",
      "Epoch: 1, Step: 2400, Loss: 4.489036560058594\n",
      "Epoch: 1, Step: 2600, Loss: 4.444291114807129\n",
      "Epoch: 1, Step: 2800, Loss: 4.1216230392456055\n",
      "Epoch: 1, Step: 3000, Loss: 4.24259614944458\n",
      "Epoch: 1, Step: 3200, Loss: 4.871382713317871\n",
      "Epoch: 1, Step: 3400, Loss: 4.784089088439941\n",
      "Epoch: 1, Step: 3600, Loss: 4.455198287963867\n",
      "Epoch: 1, Step: 3800, Loss: 4.227756500244141\n",
      "Epoch: 1, Step: 4000, Loss: 4.266725063323975\n",
      "Epoch: 1, Step: 4200, Loss: 4.198337554931641\n",
      "Epoch: 1, Step: 4400, Loss: 4.639439582824707\n",
      "Epoch: 1, Step: 4600, Loss: 4.310393333435059\n",
      "Epoch: 1, Step: 4800, Loss: 4.418458938598633\n",
      "Epoch: 2, Step: 0, Loss: 4.510066032409668\n",
      "Epoch: 2, Step: 200, Loss: 4.28679084777832\n",
      "Epoch: 2, Step: 400, Loss: 4.057429313659668\n",
      "Epoch: 2, Step: 600, Loss: 4.017435550689697\n",
      "Epoch: 2, Step: 800, Loss: 4.260326862335205\n",
      "Epoch: 2, Step: 1000, Loss: 4.244904041290283\n",
      "Epoch: 2, Step: 1200, Loss: 4.209937572479248\n",
      "Epoch: 2, Step: 1400, Loss: 4.204329013824463\n",
      "Epoch: 2, Step: 1600, Loss: 4.517030239105225\n",
      "Epoch: 2, Step: 1800, Loss: 4.092171669006348\n",
      "Epoch: 2, Step: 2000, Loss: 4.319366455078125\n",
      "Epoch: 2, Step: 2200, Loss: 4.206376075744629\n",
      "Epoch: 2, Step: 2400, Loss: 4.288994312286377\n",
      "Epoch: 2, Step: 2600, Loss: 4.206210136413574\n",
      "Epoch: 2, Step: 2800, Loss: 3.906860589981079\n",
      "Epoch: 2, Step: 3000, Loss: 4.011124610900879\n",
      "Epoch: 2, Step: 3200, Loss: 4.588627338409424\n",
      "Epoch: 2, Step: 3400, Loss: 4.546471118927002\n",
      "Epoch: 2, Step: 3600, Loss: 4.253759860992432\n",
      "Epoch: 2, Step: 3800, Loss: 4.027050495147705\n",
      "Epoch: 2, Step: 4000, Loss: 4.048105716705322\n",
      "Epoch: 2, Step: 4200, Loss: 4.00958776473999\n",
      "Epoch: 2, Step: 4400, Loss: 4.4473748207092285\n",
      "Epoch: 2, Step: 4600, Loss: 4.128186225891113\n",
      "Epoch: 2, Step: 4800, Loss: 4.219218730926514\n",
      "Epoch: 3, Step: 0, Loss: 4.316708087921143\n",
      "Epoch: 3, Step: 200, Loss: 4.085964679718018\n",
      "Epoch: 3, Step: 400, Loss: 3.903472423553467\n",
      "Epoch: 3, Step: 600, Loss: 3.8724162578582764\n",
      "Epoch: 3, Step: 800, Loss: 4.098423957824707\n",
      "Epoch: 3, Step: 1000, Loss: 4.0996575355529785\n",
      "Epoch: 3, Step: 1200, Loss: 4.0509748458862305\n",
      "Epoch: 3, Step: 1400, Loss: 4.045881748199463\n",
      "Epoch: 3, Step: 1600, Loss: 4.321198463439941\n",
      "Epoch: 3, Step: 1800, Loss: 3.9355075359344482\n",
      "Epoch: 3, Step: 2000, Loss: 4.136375904083252\n",
      "Epoch: 3, Step: 2200, Loss: 4.063497543334961\n",
      "Epoch: 3, Step: 2400, Loss: 4.149109363555908\n",
      "Epoch: 3, Step: 2600, Loss: 4.051313400268555\n",
      "Epoch: 3, Step: 2800, Loss: 3.7914605140686035\n",
      "Epoch: 3, Step: 3000, Loss: 3.850719928741455\n",
      "Epoch: 3, Step: 3200, Loss: 4.388098239898682\n",
      "Epoch: 3, Step: 3400, Loss: 4.401029586791992\n",
      "Epoch: 3, Step: 3600, Loss: 4.105796813964844\n",
      "Epoch: 3, Step: 3800, Loss: 3.9002163410186768\n",
      "Epoch: 3, Step: 4000, Loss: 3.915526866912842\n",
      "Epoch: 3, Step: 4200, Loss: 3.873472213745117\n",
      "Epoch: 3, Step: 4400, Loss: 4.3138861656188965\n",
      "Epoch: 3, Step: 4600, Loss: 4.0028815269470215\n",
      "Epoch: 3, Step: 4800, Loss: 4.0915608406066895\n",
      "Epoch: 4, Step: 0, Loss: 4.178753852844238\n",
      "Epoch: 4, Step: 200, Loss: 3.948330879211426\n",
      "Epoch: 4, Step: 400, Loss: 3.7996222972869873\n",
      "Epoch: 4, Step: 600, Loss: 3.7657358646392822\n",
      "Epoch: 4, Step: 800, Loss: 3.9829049110412598\n",
      "Epoch: 4, Step: 1000, Loss: 3.9883315563201904\n",
      "Epoch: 4, Step: 1200, Loss: 3.939701557159424\n",
      "Epoch: 4, Step: 1400, Loss: 3.9335241317749023\n",
      "Epoch: 4, Step: 1600, Loss: 4.19188117980957\n",
      "Epoch: 4, Step: 1800, Loss: 3.8170528411865234\n",
      "Epoch: 4, Step: 2000, Loss: 4.022946834564209\n",
      "Epoch: 4, Step: 2200, Loss: 3.947917938232422\n",
      "Epoch: 4, Step: 2400, Loss: 4.060563564300537\n",
      "Epoch: 4, Step: 2600, Loss: 3.9448344707489014\n",
      "Epoch: 4, Step: 2800, Loss: 3.679657459259033\n",
      "Epoch: 4, Step: 3000, Loss: 3.7429115772247314\n",
      "Epoch: 4, Step: 3200, Loss: 4.246902942657471\n",
      "Epoch: 4, Step: 3400, Loss: 4.300748348236084\n",
      "Epoch: 4, Step: 3600, Loss: 4.013528823852539\n",
      "Epoch: 4, Step: 3800, Loss: 3.7992420196533203\n",
      "Epoch: 4, Step: 4000, Loss: 3.815964698791504\n",
      "Epoch: 4, Step: 4200, Loss: 3.7752909660339355\n",
      "Epoch: 4, Step: 4400, Loss: 4.221454620361328\n",
      "Epoch: 4, Step: 4600, Loss: 3.908679246902466\n",
      "Epoch: 4, Step: 4800, Loss: 3.993168354034424\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "sched = CosineAnnealingLR(opt, epochs * len(dl), lr * 0.5)\n",
    "for i in range(epochs):\n",
    "    for step, (xb, yb) in enumerate(dl):\n",
    "        opt.zero_grad()\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "            logits, loss = model(xb, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        if step % 200 == 0 or step == len(dl) - 1:\n",
    "            print(f\"Epoch: {i}, Step: {step}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "884e3ee7-4ae5-453f-8447-43800b86d57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19236689"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64fc4809-41e4-4bcb-ba06-bca688f547f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(idx, max_tokens):\n",
    "    model.eval()\n",
    "    tokens = idx\n",
    "    for i in range(max_tokens):\n",
    "        logits = model(tokens[:, -context_length:])\n",
    "        topk_values, topk_indices = torch.topk(logits[:, -1, :], 20)\n",
    "        probs = topk_values.softmax(dim=-1)\n",
    "        sample = torch.multinomial(probs, 1)\n",
    "        token = torch.gather(topk_indices, 1, sample)\n",
    "        tokens = torch.cat((tokens, token), dim=-1)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a718bb-5a54-4d79-b93d-6c986844f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tokens = tokenizer.encode(\"What do you call a\", return_tensors='pt').to(device)\n",
    "print(tokenizer.decode(generate(start_tokens, 2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca9309d-a870-49ac-9a94-2c3228e4c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/jokes_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b87bee-32d3-4894-8695-37e68be57e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
