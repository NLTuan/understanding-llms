{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618854aa-8df4-40d7-b956-638642501e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2bafad-be25-4e89-87d6-9234a12dcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"openai-community/gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3b5f1b-da64-4cca-944a-19e4f69bb5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"myothiha/jokes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c4e458-ed92-4624-9926-cb1ec48ed34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187641"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ds['train']['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5033d2e9-182a-4cc1-bc3e-37b1c5eb6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<|endoftext|>'.join(ds['train']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374a5ff0-ca55-4e96-82cf-a4c00b6d8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "context_length = 32\n",
    "n_embs = 128\n",
    "n_heads = 16\n",
    "n_blocks = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1678e521-f353-49cb-bd00-070a8844052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf0edb3-4b5f-417b-b9d6-03f225622f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataLoader():\n",
    "    def __init__(self, text, context_length, tokenizer, batch_size=1, device='cpu'):\n",
    "        v = tokenizer(text, return_tensors='pt')\n",
    "        self.tokens = v.input_ids # The attention mask will be handled manually later\n",
    "        self.batch_size = batch_size\n",
    "        self.context_length = context_length\n",
    "        self.device = device\n",
    "        \n",
    "        self.position = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.reset()\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        B, T = self.batch_size, self.context_length\n",
    "        if self.position + B * T + 1 < len(self.tokens[0]):\n",
    "            tokens = self.tokens[0][self.position: self.position + B * T + 1]\n",
    "            self.position += B * T + 1\n",
    "            x = tokens[:-1].view(B, T)\n",
    "            y = tokens[1:].view(B, T)\n",
    "            return x.to(self.device), y.to(self.device)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.tokens[0]) // (self.context_length + 1) // self.batch_size\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bff33-94ea-4d42-8d21-d533aec74ef2",
   "metadata": {},
   "source": [
    "The `head_size` matches that of the embeddings if it is a single head.\n",
    "\n",
    "If multi-headed attention is used, then the `head_size` would equal number of embeddings // number of heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03339711-a3e5-47a4-923d-4f077210e85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttentionHead(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.k = nn.Linear(n_embs, head_size, bias=False)\n",
    "        self.q = nn.Linear(n_embs, head_size, bias=False)\n",
    "        self.v = nn.Linear(n_embs, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.k(x) # (B, T, head_size)\n",
    "        q = self.q(x) # (B, T, head_size)\n",
    "        v = self.v(x) # (B, T, head_size)\n",
    "        \n",
    "#         attn = q @ k.transpose(-2, -1) * C ** -0.5 # (B, T, T)\n",
    "        \n",
    "#         wei = attn.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) # Causal masking, blocks future tokens from being seen\n",
    "#         wei = wei.softmax(dim=-1) # (B, T, T)\n",
    "        \n",
    "#         out = wei @ v # (B, T, head_size)\n",
    "        out = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b400d5-aa6a-4b65-b8d6-dc914cda5587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttentionHead(n_embs // n_heads) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embs, n_embs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92b6718-a1ae-4ea6-bcc5-93455857d8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embs, n_embs * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_embs * 4, n_embs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26fe11e4-11a7-446a-9460-b06516801701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(n_embs)\n",
    "        self.mha = MultiHeadAttention(n_heads)\n",
    "        self.ln2 = nn.LayerNorm(n_embs)\n",
    "        self.ffwd = FeedForward()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.mha(self.ln1(x)) + x\n",
    "        x = self.ffwd(self.ln2(x)) + x\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f0c74a-c31f-4d47-993d-4ee10741d6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tk_emb = nn.Embedding(vocab_size, n_embs)\n",
    "        self.pos_emb = nn.Embedding(context_length, n_embs)\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock() for i in range(n_blocks)])\n",
    "        self.ln_f = nn.LayerNorm(n_embs)\n",
    "        self.fc = nn.Linear(n_embs, vocab_size)\n",
    "        \n",
    "        self.tk_emb.weight = self.fc.weight\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        tk_emb = self.tk_emb(x) # (B, T, C)\n",
    "        pos_tns = torch.arange(T, device=device) # T\n",
    "        pos_emb = self.pos_emb(pos_tns) # (T, C)\n",
    "        x = pos_emb + tk_emb # (B, T, C) + (T, C)\n",
    "        \n",
    "        x = self.blocks(x)\n",
    "        \n",
    "        x = self.ln_f(x)\n",
    "        logits = self.fc(x) # (B, T, vocab_size)\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(B * T, -1), targets.view(B*T))\n",
    "            return logits, loss\n",
    "        \n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735c13f3-b7b2-41c9-bf40-122942bd1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(mod):\n",
    "    if isinstance(mod, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(mod.weight)\n",
    "        if mod.bias is not None:\n",
    "            torch.nn.init.zeros_(mod.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c67e5f02-78a0-4730-979d-1f31dbab1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e125af26-a85c-4b2d-96d8-0eb3cd1f50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TextDataLoader(text, context_length, tokenizer, batch_size=32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b7d3942-19bd-41ab-b090-21be4608e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4425, 4673544)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl), len(dl.tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3388084f-a00e-4a00-91d7-c6e11018c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8070609"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT().to(device)\n",
    "model.apply(initialize)\n",
    "lr = 7e-4\n",
    "opt = optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2143b478-bf90-4f10-bf0f-eb2416bf035d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1014,  0.4470,  3.4385,  ..., -1.4988,  2.6929, -0.9296],\n",
       "          [ 0.4989,  0.4790,  1.0835,  ..., -2.0187,  3.2798,  0.0661],\n",
       "          [ 0.2977,  1.6409,  0.7137,  ..., -1.7743,  3.7793, -0.5917],\n",
       "          ...,\n",
       "          [ 1.2270,  1.0936,  0.1648,  ..., -1.2649,  2.5656, -1.3216],\n",
       "          [ 0.6957,  0.4822, -1.5492,  ..., -1.6905,  3.2747, -0.7123],\n",
       "          [ 1.9623,  0.7844,  0.5086,  ..., -1.9630,  1.8272,  0.3836]],\n",
       " \n",
       "         [[-0.2554,  0.1965,  3.8129,  ..., -1.3376,  2.5233, -1.2478],\n",
       "          [ 0.7708,  0.3430,  1.2166,  ..., -1.5564,  3.2044, -0.0356],\n",
       "          [ 0.5501,  1.3278,  0.8737,  ..., -1.6529,  3.5425, -0.5093],\n",
       "          ...,\n",
       "          [ 1.9153,  0.8677,  0.9645,  ..., -0.9940,  2.0926, -1.9137],\n",
       "          [ 0.2208,  0.4363, -0.2117,  ..., -1.3752,  2.6518, -1.7363],\n",
       "          [ 1.9874,  0.9801,  1.0197,  ..., -1.5811,  1.9959, -0.2106]],\n",
       " \n",
       "         [[-0.2723,  0.3089,  3.5559,  ..., -1.5968,  2.6581, -1.1554],\n",
       "          [ 0.7796,  0.2458,  0.7282,  ..., -1.7540,  3.3448, -0.1109],\n",
       "          [ 0.4740,  1.5381, -0.4697,  ..., -1.4260,  3.3765, -0.4237],\n",
       "          ...,\n",
       "          [ 1.5415,  0.9007,  0.2071,  ..., -0.9057,  1.6834, -1.5696],\n",
       "          [ 0.9899,  0.3129, -0.4470,  ..., -1.3874,  3.6785, -1.4087],\n",
       "          [ 1.8467,  0.4148,  0.4908,  ..., -1.6375,  1.6944, -0.3485]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1654,  0.2881,  3.1417,  ..., -1.7481,  2.7041, -1.0199],\n",
       "          [ 0.8146,  0.5253,  0.6598,  ..., -2.0070,  3.4150,  0.0469],\n",
       "          [ 0.0508,  1.3508, -0.2972,  ..., -1.3003,  3.5347, -0.7518],\n",
       "          ...,\n",
       "          [ 1.4740,  0.6750,  0.4994,  ..., -0.7814,  2.2089, -1.5094],\n",
       "          [ 1.0349, -0.0930, -0.7480,  ..., -1.5087,  3.5912, -2.0742],\n",
       "          [ 2.0056,  0.4551,  0.4895,  ..., -1.7799,  1.8168,  0.0657]],\n",
       " \n",
       "         [[-0.1625,  0.1661,  3.4563,  ..., -1.4073,  2.5808, -1.0181],\n",
       "          [ 0.8824,  0.3873,  0.7510,  ..., -1.5576,  3.3486, -0.1824],\n",
       "          [ 0.5792,  0.9750, -0.8255,  ..., -1.3363,  3.4806, -0.2341],\n",
       "          ...,\n",
       "          [ 1.2909,  1.0049,  0.0812,  ..., -1.1704,  1.5757, -1.1286],\n",
       "          [ 1.0068,  0.6931, -0.7008,  ..., -1.3576,  3.6719, -1.1493],\n",
       "          [ 1.6726,  0.7119,  0.7044,  ..., -1.7407,  1.7608,  0.4317]],\n",
       " \n",
       "         [[ 0.0124,  0.2370,  3.3495,  ..., -1.4978,  2.7402, -1.1155],\n",
       "          [ 1.0308,  0.5018,  0.6486,  ..., -2.0271,  3.4266, -0.0284],\n",
       "          [ 0.4652,  1.4853,  0.2878,  ..., -1.8090,  3.2400, -0.0904],\n",
       "          ...,\n",
       "          [ 1.5026,  0.6817,  0.8579,  ..., -1.3017,  1.9612, -1.1992],\n",
       "          [ 1.2175,  0.8314, -1.0679,  ..., -1.5723,  3.5602, -1.8939],\n",
       "          [ 1.9228,  0.9606,  1.2351,  ..., -1.3683,  1.5856,  0.3800]]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " tensor(11.8747, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl))\n",
    "model(x=xb, targets=yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a182f-e2a0-42c2-bd90-86e2b2a19ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 11.87548828125\n",
      "Epoch: 0, Step: 442, Loss: 6.692626476287842\n",
      "Epoch: 0, Step: 884, Loss: 5.980865001678467\n",
      "Epoch: 0, Step: 1326, Loss: 5.669127464294434\n",
      "Epoch: 0, Step: 1768, Loss: 5.592933177947998\n",
      "Epoch: 0, Step: 2210, Loss: 5.366819381713867\n",
      "Epoch: 0, Step: 2652, Loss: 5.201066970825195\n",
      "Epoch: 0, Step: 3094, Loss: 5.23137903213501\n",
      "Epoch: 0, Step: 3536, Loss: 4.969971179962158\n",
      "Epoch: 0, Step: 3978, Loss: 5.185560703277588\n",
      "Epoch: 0, Step: 4420, Loss: 4.611307621002197\n",
      "Epoch: 0, Step: 4425, Loss: 5.228513717651367\n",
      "Epoch: 1, Step: 0, Loss: 5.138219833374023\n",
      "Epoch: 1, Step: 442, Loss: 5.167189121246338\n",
      "Epoch: 1, Step: 884, Loss: 4.924767971038818\n",
      "Epoch: 1, Step: 1326, Loss: 4.846548080444336\n"
     ]
    }
   ],
   "source": [
    "# Training loop for pre-training\n",
    "epochs = 5\n",
    "sched = CosineAnnealingLR(opt, epochs * len(dl), lr * 0.01)\n",
    "for i in range(epochs):\n",
    "    for step, (xb, yb) in enumerate(dl):\n",
    "        opt.zero_grad()\n",
    "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "            logits, loss = model(xb, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        if step % (len(dl)//10) == 0 or step == len(dl):\n",
    "            print(f\"Epoch: {i}, Step: {step}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64fc4809-41e4-4bcb-ba06-bca688f547f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(idx, max_tokens):\n",
    "    model.eval()\n",
    "    tokens = idx\n",
    "    for i in range(max_tokens):\n",
    "        logits = model(tokens[:, -context_length:])\n",
    "        topk_values, topk_indices = torch.topk(logits[:, -1, :], 50)\n",
    "        probs = topk_values.softmax(dim=-1)\n",
    "        sample = torch.multinomial(probs, 1)\n",
    "        token = torch.gather(topk_indices, 1, sample)\n",
    "        tokens = torch.cat((tokens, token), dim=-1)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4a0d07-88e0-40f8-8af6-b49a900f3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a girl who was an common like a bad? A chicken out between a cow? The bartender doesn't a big.\n",
      "<|endoftext|>If a man is no new job, she'll be a new lot.\n",
      "<|endoftext|>What's your computer got on me? The difference between his mother's and that it's a woman\n",
      "<|endoftext|>They don't take a job. The bartender asks 'pats a picture.\n",
      "<|endoftext|>Why can't gay and black people get up? Because he lost two things on his house.\n",
      "<|endoftext|>I went to the only I have a job. I'm in bed, you don't tell it.\n",
      "<|endoftext|>My phone is a dyslexon, but I want to eat.\n",
      "<|endoftext|>What's the difference between a pirate and a joke? The difference between a bar and 1, and both he says, there's a long time, it's a man in.\n",
      "<|endoftext|>My wife's best friend who had to look a long car? My father asked me I'll just like a group.\n",
      "<|endoftext|>Did you hear about the people about the guy who told you get it the toilet? They haven't believe he's only.\n",
      "<|endoftext|>I bet I could pick some things about a dog... but we can't believe it\n",
      "<|endoftext|>I like my kids like my coffee's time she thought, \"\"I love you and know I had a problem.\"\"\n",
      "<|endoftext|>What do you give a penis with a chick? Qu-\" - the woman and no joke out, \"\"I can get on me and see it's, then they just think the first thing!\n",
      "<|endoftext|>It's so much, and I saw to be in the way I can come out of my own.\n",
      "<|endoftext|>Why is the difference between a joke and a Jew? So men would be been an dead girl, a black-re and the best was more.\n",
      "<|endoftext|>What is the difference between an Irish and a horse? A fis.\n",
      "<|endoftext|>Me says: If you are married\n",
      "<|endoftext|>i know you feel the time in me, you don't even serve a few. (It can do you know that of two of the man.\n",
      "<|endoftext|>What do you call the computer when a guy asked the man is to give a Mexican? You've never had a bit home\n",
      "<|endoftext|>How does an black guy eat? He don't want it in a car.\n",
      "<|endoftext|>How many people does there take to win a lightbul bulb? None, you don't believe it but it's like the best.\n",
      "<|endoftext|>I told my friends I'd just told it's \"\"The doctor\"\" would even have a one way. And I'll keep a little race.\n",
      "<|endoftext|>Why do a pirate go to a gay? The other was a woman-year-f. He just tried to go out of a woman on a lightbulopus in your car and a bit-old, that means.\n",
      "<|endoftext|>What is an the priest  father's favorite place in his mouth? The middle guy\n",
      "<|endoftext|>Why did the new dog cross the road? It's only much to the car\n",
      "<|endoftext|>What long did the joke go to the bartender? You don't.\n",
      "<|endoftext|>My wife is just a girl who wants to get a long joke if I mean she had her at the rest.\n",
      "<|endoftext|>DI need to eat a lot until she's a piece of fun.\n",
      "<|endoftext|>The difference between a man asked her words \"\"I don't\"\" you'm gonna let it's very long day\"\"\n",
      "<|endoftext|>Why did Hillary never take the day on the sea without his own life? He got the next-wife.\n",
      "<|endoftext|>What do you do when you cross a blonde with an pizza? A legs.\n",
      "<|endoftext|>My wife's new hands is sure to go.\n",
      "<|endoftext|>I went up with the bar The first day, but I could put him so much my face.\n",
      "<|endoftext|>What happens to the best part across a wall? \"\"And you really want them on you.\n",
      "<|endoftext|>What do you get when you were an gay man than a woman? A few.\n",
      "<|endoftext|>Why was Hitler so much? Because he can't be any!\n",
      "<|endoftext|>Why did the cannibal go out? Because he'd only want to live out.\n",
      "<|endoftext|>There who were a little joke in the road. I don't know that I'm a kid.\n",
      "<|endoftext|>Why should someone become a bad joke from bed? Because they've been bad on the time, but it is sure.\n",
      "<|endoftext|>If you a lot out of a lot of Facebook, I'd've been a new girl.\n",
      "<|endoftext|>Why couldn't the man see the moon? I won't.\n",
      "<|endoftext|>I'm going to catch it, but I'm too much, so, it's always doing you...\n",
      "<|endoftext|>The only joke so I'm going to be a new hand... It's just a only way, she's just sure that \"\"That's what he can be me?\"\"\n",
      "<|endoftext|>This person that there is a little black and a joke... There's the time.\n",
      "<|endoftext|>The only big-old is a little girl.\n",
      "<|endoftext|>It died like I'm so good... ...but I'm so the \"\"r' and that's like you want?\"\"\n",
      "<|endoftext|>S's like a great girl of a big penis?\n",
      "<|endoftext|>Why doesn't the jew go for the rest of the road? It's \"\"a and get sure at 3's on you! I'm pretty done.\n",
      "<|endoftext|>\"\"Sorry, are your job, you were in the moon!\"\" -You're not so fat in a lot of a bar.\n",
      "<|endoftext|>So I was fired about the first day... It's like I mean....\n",
      "<|endoftext|>\"\"Well guys! What happened in a penis? you really think the police are!\"\"\n",
      "<|endoftext|>Why did the chicken fight cross the road? To take him a time out.\n",
      "<|endoftext|>How many lesbians does it take and the world does a good girl? They never got to be a joke.\n",
      "<|endoftext|>Two Freudian joke does it take to screw your penis? That is a shit.\n",
      "<|endoftext|>Why did the people use his girlfriend? He was arrested with a good house.\n",
      "<|endoftext|>I hate the way to the first day I said how I've got her long, I'm for them, but I don't mean he got the time about the name.\n",
      "<|endoftext|>What do people have to screw in a lightbulb? One-b\n",
      "<|endoftext|>Cent have been so far, it's an own penis in the car.\n",
      "<|endoftext|>How many feminists does it take his wife's lightbulb? A man says, \"\"What is you like a light\"\n",
      "<|endoftext|>Two blondic, at the street and a black man were in a bar. The other says, \"\"I'm that in the first.\"\"\n",
      "<|endoftext|>They make your coffee. I'm in a new bar at her.\n",
      "<|endoftext|>I wish why the woman like I saw a one while.\n",
      "<|endoftext|>What does a girl say when he had a lot off from her legs?\n",
      "<|endoftext|>Why come like he found them in their food? A: He got no kids for the day.\n",
      "<|endoftext|>Jold at least I would have a good person.\n",
      "<|endoftext|>The last thing your dog was going to the first day...\n",
      "<|endoftext|>Two people with a new computer... The bartender looks up the otherman says \"\"I hope I can only see you\"\" Then that I won't get on your bed.\n",
      "<|endoftext|>Is I just like a man and a gay joke at this morning? I think it has him, because I want more up a lot.\n",
      "<|endoftext|>In 10-shr's all to play. We think it's like I do it.\n",
      "<|endoftext|>What do you give a man who is making sex on 3 times? Your mouth.\n",
      "<|endoftext|>I got one like the biggest hour, I'll put this day for my house. She said he had one to become another time and just didn't make it.\n",
      "<|endoftext|>A man told me... when I tried to leave her \"\"s, I think you can run up'\"\"\n",
      "<|endoftext|>I've been been a new place... ...but I found a lot of a group. He wasn't a better person.\n",
      "<|endoftext|>What a hippman do you call a cow when it is for your best. The doctor got a good box in the fridge and says, \"\"I went off out\"\"\n",
      "<|endoftext|>What's the difference between a garper and a snowbo? The bartender responds that it was dead\n",
      "<|endoftext|>I was going to put a bar. If you're a baby, and it's just, I saw an new car, but then says I got one.\n",
      "<|endoftext|>What's the difference between a baby and an pedophile? a woman couldn't make your hair.\n",
      "<|endoftext|>I tried out and said \"\"Buck!\"\" with my dad until I went more than her time.\n",
      "<|endoftext|>Just got my coffee, but it's pretty much... so what I'm pretty much from any money.\n",
      "<|endoftext|>\"\"You can't feel not like it. It's just much.\"\" But I've been going on my house I said it was already a bit of me!\n",
      "<|endoftext|>I never asked the woman today. He said, \"\"Wow it, I can't go you a bad one?\"\" and asked it, \"\"Who did you have a girl?\"\" The horse says, \"\"So, what kind of you?\n",
      "<|endoftext|>I don't take the toilet for my ear-drows. I said to be in my ear.\n",
      "<|endoftext|>It's a baby that just said 'it is like this people in the head.\n",
      "<|endoftext|>When I have the funnster I went down and I am so I'm very like it would only be that I'll be sure\n",
      "<|endoftext|>What looks on a difference between two cat and a woman? Two guys has on a cliff\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "start_tokens = tokenizer.encode(\"What do you call\", return_tensors='pt').to(device)\n",
    "print(tokenizer.decode(generate(start_tokens, 2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9309d-a870-49ac-9a94-2c3228e4c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"models/jokes_transformer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
